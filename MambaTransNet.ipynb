{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e676fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "=== 1. Core Dependencies ===\n",
      "\n",
      "=== 2. VMamba CUDA Kernel (ss2d) ===\n",
      "Current GPU: Tesla T4 (sm_75)\n",
      "Cache arch matches current GPU (sm_75) ✓\n",
      "Cache found! Restoring 1 kernel files...\n",
      "  Restored: selective_scan_cuda_oflex.cpython-312-x86_64-linux-gnu.so -> /usr/local/lib/python3.12/dist-packages/selective_scan_cuda_oflex.cpython-312-x86_64-linux-gnu.so\n",
      "selective_scan_cuda_oflex imported OK (sm_75)\n",
      "\n",
      "=== Setup Complete ===\n",
      "Project: /content/drive/MyDrive/MambaCompression\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.5/444.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Environment Setup (with kernel caching)\n",
    "# ============================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "exec(open(\"/content/drive/MyDrive/MambaCompression/setup_colab.py\").read())\n",
    "!pip install compressai --quiet 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Full RP-MPQ Analysis (INT8 + Quantization)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_L2_dim512_baseline/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 512 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --learning-rate 1e-3 \\\n",
    "  --decoder_layers 2 \\\n",
    "  --encoder_layers 2 \\\n",
    "  --batch-size 200 \\\n",
    "  --num-workers 4 \\\n",
    "  --quant_type asym \\\n",
    "  --pq INT8 \\\n",
    "  --aq 8 \\\n",
    "  --act_quant 16 \\\n",
    "  --analyze_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b121a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: FP32 Baseline Inference (No Quantization)\n",
    "# Expected NMSE: -15.34 dB (outdoor, mamba+transnet, dim=512)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_L2_dim512_baseline/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 512 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --decoder_layers 2 \\\n",
    "  --encoder_layers 2 \\\n",
    "  --batch-size 200 \\\n",
    "  --test-batch-size 200 \\\n",
    "  --num-workers 4 \\\n",
    "  --pq FP32 \\\n",
    "  --aq 0 \\\n",
    "  --act_quant 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i3yncwwy8x",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Mamba-Transformer AE CR=1/4 Uniform Quantization Sweep\n",
    "# Weights: INT16 / INT8 / INT4 / INT2,  Activations: INT16 (fixed)\n",
    "# Latent: 8-bit (--aq 8, CsiNet/CLNet과 동일 조건)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "BASE = (\n",
    "    \"python train_ae.py\"\n",
    "    \" --checkpoint saved_models/mamba_transnet_L2_dim512_baseline/best.pth\"\n",
    "    \" --encoder mamba --decoder transnet --encoded_dim 512\"\n",
    "    \" --train_path data/DATA_Htrainout.mat --test_path data/DATA_Htestout.mat\"\n",
    "    \" --epochs 0 --decoder_layers 2 --encoder_layers 2\"\n",
    "    \" --batch-size 200 --test-batch-size 200 --num-workers 2\"\n",
    "    \" --aq 8 --act_quant 16\"\n",
    ")\n",
    "\n",
    "for prec in [\"INT16\", \"INT8\", \"INT4\", \"INT2\"]:\n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"# Running: W={prec}  A=INT16  Latent=8bit\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    !{BASE} --pq {prec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y23xqce9rrl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5: RP-MPQ Offline Policy Search (ILP + KL Refinement)\n",
    "# Figure 2: ILP vs KL-refined policy evaluation\n",
    "# Range: 75% ~ 95% BOPs Saving | Step: 0.5% | KL Candidates: 10\n",
    "# Output: results/csv/mp_policy_lut_mamba_raw.csv      ← raw (새로 추가)\n",
    "#         results/csv/mp_policy_lut_mamba_pruned.csv   ← monotonic smoothed\n",
    "#         results/csv/fitting_raw_data_mamba.csv\n",
    "#         results/plots/exp1_pareto_accuracy_mamba_raw.png       ← raw 그림 (별도)\n",
    "#         results/plots/exp1_pareto_accuracy_mamba_monotonic.png ← monotonic 그림 (별도)\n",
    "#         ../figures/kl_vs_ilp_raw.pdf\n",
    "#         ../figures/kl_vs_ilp_monotonic.pdf\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "import os\n",
    "csv_dir = \"results/csv\"\n",
    "for f in [\"mp_policy_lut_mamba_pruned.csv\",\n",
    "          \"mp_policy_lut_mamba_raw.csv\",\n",
    "          \"fitting_raw_data_mamba.csv\"]:\n",
    "    p = os.path.join(csv_dir, f)\n",
    "    if os.path.exists(p):\n",
    "        os.remove(p)\n",
    "        print(f\"Removed: {p}\")\n",
    "\n",
    "!pip install pulp -q\n",
    "\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_L2_dim512_baseline/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 512 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --decoder_layers 2 \\\n",
    "  --encoder_layers 2 \\\n",
    "  --batch-size 200 \\\n",
    "  --test-batch-size 200 \\\n",
    "  --num-workers 2 \\\n",
    "  --pq INT8 \\\n",
    "  --aq 8 \\\n",
    "  --act_quant 16 \\\n",
    "  --analyze_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5azx5v50s8n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Mamba-Transformer AE  CR=1/16  Training  (1000 epochs, resumable)\n",
    "#\n",
    "# Resume logic:\n",
    "#   - best.pth가 존재하면 저장된 절대 epoch을 읽어 남은 epoch만 학습\n",
    "#   - Colab이 꺼져도 다시 이 셀을 실행하면 정확히 이어서 학습\n",
    "#   - 모델 저장 경로: saved_models/mamba_transnet_dim128_cr16/best.pth\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "import os, torch\n",
    "\n",
    "# ── Config ──────────────────────────────────────────────────────────────\n",
    "SAVE_DIR      = \"saved_models/mamba_transnet_dim128_cr16\"\n",
    "TARGET_EPOCHS = 1000\n",
    "ENCODED_DIM   = 128          # CR = 1/16  (2048 / 16)\n",
    "LR            = 1e-3\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "ckpt = f\"{SAVE_DIR}/best.pth\"\n",
    "\n",
    "# ── Resume 포인트 결정 (절대 epoch 기준) ─────────────────────────────────\n",
    "if os.path.isfile(ckpt):\n",
    "    state = torch.load(ckpt, map_location=\"cpu\")\n",
    "    done      = int(state.get(\"epoch\", -1)) + 1   # 절대 epoch (누적)\n",
    "    remaining = TARGET_EPOCHS - done\n",
    "    print(f\"[Resume] Checkpoint found  →  epoch {done}/{TARGET_EPOCHS} done, {remaining} remaining\")\n",
    "else:\n",
    "    done      = 0\n",
    "    remaining = TARGET_EPOCHS\n",
    "    print(f\"[Fresh ] No checkpoint     →  training from scratch for {remaining} epochs\")\n",
    "\n",
    "if remaining <= 0:\n",
    "    print(f\"[Done  ] Already reached {TARGET_EPOCHS} epochs. Run the inference cell below.\")\n",
    "else:\n",
    "    print(f\"[Train ] Running {remaining} epoch(s)  (best.pth → {SAVE_DIR})\\n\")\n",
    "    !python train_ae.py \\\n",
    "      --encoder mamba \\\n",
    "      --decoder transnet \\\n",
    "      --encoded_dim {ENCODED_DIM} \\\n",
    "      --save_dir    {SAVE_DIR} \\\n",
    "      --checkpoint  {ckpt} \\\n",
    "      --start_epoch {done} \\\n",
    "      --train_path  data/DATA_Htrainout.mat \\\n",
    "      --test_path   data/DATA_Htestout.mat \\\n",
    "      --epochs      {remaining} \\\n",
    "      --learning-rate {LR} \\\n",
    "      --decoder_layers 2 \\\n",
    "      --encoder_layers 2 \\\n",
    "      --batch-size      200 \\\n",
    "      --test-batch-size 200 \\\n",
    "      --num-workers 4 \\\n",
    "      --pq FP32 --aq 0 --act_quant 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12oimvh3k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 7: Mamba-Transformer AE  CR=1/16  FP32 Inference\n",
    "# Expected: NMSE (dB), Enc FLOPs, Total FLOPs\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_dim128_cr16/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 128 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path  data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --decoder_layers 2 \\\n",
    "  --encoder_layers 2 \\\n",
    "  --batch-size      200 \\\n",
    "  --test-batch-size 200 \\\n",
    "  --num-workers 4 \\\n",
    "  --pq FP32 --aq 0 --act_quant 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5p5ya66l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 8: Budget Consistency Validation  ← Table III in paper\n",
    "# \"Budget Consistency under Online RP-MPQ\"\n",
    "#\n",
    "# Prerequisites:\n",
    "#   - Cell 5 완료 (mp_policy_lut_mamba_pruned.csv 존재)\n",
    "#   - best.pth 체크포인트 존재\n",
    "#\n",
    "# 소요시간: ~20-30min (GPU)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "import os\n",
    "\n",
    "LOG = \"results/csv/exp4_budget_run.log\"\n",
    "\n",
    "# ── Step 1: Run (stdout+stderr → log file so nothing is truncated) ──────\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_L2_dim512_baseline/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 512 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path  data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --decoder_layers 2 --encoder_layers 2 \\\n",
    "  --batch-size 200 --test-batch-size 200 \\\n",
    "  --num-workers 2 \\\n",
    "  --aq 8 --act_quant 16 \\\n",
    "  --analyze_all \\\n",
    "  > {LOG} 2>&1 && echo \"✅ Done\" || echo \"❌ Script failed — see log\"\n",
    "\n",
    "# ── Step 2: Check last 60 lines of log (errors are usually at the end) ──\n",
    "print(\"\\n─── Last 60 lines of log ────────────────────────────────────────\")\n",
    "with open(LOG) as f:\n",
    "    lines = f.readlines()\n",
    "for l in lines[-60:]:\n",
    "    print(l, end=\"\")\n",
    "\n",
    "# ── Step 3: Display Budget Consistency Table (if CSV updated) ────────────\n",
    "print(\"\\n\\n─── Budget Consistency Table ────────────────────────────────────\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_path = \"results/csv/ranc_simulation_results_mamba.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "if 'Target_Saving' not in df.columns:\n",
    "    print(\"\\n[WARNING] Old CSV format — exp4 failed to overwrite.\")\n",
    "    print(\"Scroll up or open the log file for the traceback:\")\n",
    "    print(f\"  → {os.path.abspath(LOG)}\")\n",
    "else:\n",
    "    sub = (df[(df['SNR_Context'] == 20) & (df['QoS_Target'] == 0.99)]\n",
    "             [['Target_Saving', 'Realized_Saving', 'Lambda']]\n",
    "             .drop_duplicates('Target_Saving')\n",
    "             .sort_values('Target_Saving')\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "    sub['Deviation (%)'] = (\n",
    "        (sub['Realized_Saving'] - sub['Target_Saving']).abs()\n",
    "        / sub['Target_Saving'] * 100\n",
    "    ).round(3)\n",
    "\n",
    "    rep = [87.5, 90.0, 92.5]\n",
    "    mask = sub['Target_Saving'].round(1).isin(rep)\n",
    "    table = sub[mask].copy() if mask.any() else sub.iloc[len(sub)//4 : 3*len(sub)//4 : max(1, len(sub)//4)]\n",
    "\n",
    "    print(table[['Target_Saving', 'Realized_Saving', 'Deviation (%)']].to_string(index=False))\n",
    "    print(f\"\\n  Max deviation: {table['Deviation (%)'].max():.3f}%\")\n",
    "\n",
    "    print(\"\\n─── LaTeX rows ─────────────────────────────────────────────────\")\n",
    "    for _, row in table.iterrows():\n",
    "        t, r, d = row['Target_Saving'], row['Realized_Saving'], row['Deviation (%)']\n",
    "        print(f\"  ${t:.1f}\\\\%$ & ${r:.2f}\\\\%$ & ${d:.3f}$ \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78j7b54hji",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MambaCompression/MambaIC\n",
      "--- Start: 2026-02-24 07:23:23.689991 ---\n",
      "[INFO] Config: W:[INT8] A:[INT16] FB:[8-bit]\n",
      "    Hybrid: False | Chunking: False\n",
      "[INFO] Device: CUDA\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/models/VSS_module.py:56: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/models/VSS_module.py:64: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/models/VSS_module.py:217: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/models/VSS_module.py:225: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/models/VSS_module.py:239: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/models/VSS_module.py:247: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Warning: mamba_ssm not found. 1D Scan modes disabled.\n",
      "[INFO] Building: UE Encoder [mamba-L2] + BS Decoder [transnet-L2]\n",
      "/content/drive/MyDrive/MambaCompression/MambaIC/train_ae.py:2114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(device == 'cuda'))\n",
      "[INFO] Loaded existing HAWQ results: /content/drive/MyDrive/MambaCompression/MambaIC/results/csv/hawq_importance_split.csv\n",
      "\n",
      "[INFO] Starting unified scan... (85-98% | 0.05% step)\n",
      "\n",
      "[INFO] Offline Policy Search: Range 85-95% | Step 0.1% | Points: 261\n",
      "Scanning Pareto & Calibration: 100% 261/261 [42:41<00:00,  9.82s/it]\n",
      "\n",
      "[INFO] Offline policy set + calibration data saved.\n",
      "[INFO] Saved: /content/drive/MyDrive/MambaCompression/MambaIC/results/plots/exp1_pareto_accuracy_mamba_raw.png\n",
      "Figure(700x450)\n",
      "[INFO] Saved: /content/drive/MyDrive/MambaCompression/MambaIC/results/plots/exp1_pareto_accuracy_mamba_monotonic.png\n",
      "Figure(700x450)\n",
      "[INFO] Pruned LUT saved to: /content/drive/MyDrive/MambaCompression/MambaIC/results/csv/mp_policy_lut_mamba_pruned.csv\n",
      "\n",
      "[INFO] Wide sweep complete. LUT saved → /content/drive/MyDrive/MambaCompression/MambaIC/results/csv/mp_policy_lut_mamba_wide_pruned.csv\n",
      "[INFO] Skipping Exp 3/3.5/4 (wide sweep has no calibration data).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 9: RP-MPQ Offline Wide Sweep (85–98%, 0.05% Step)\n",
    "#\n",
    "# 목적: ILP prediction vs KL refinement 비교 (raw + monotonic smoothed)\n",
    "# Prerequisites:\n",
    "#   - Cell 1 (환경 설정) 완료\n",
    "#   - HAWQ results 존재 (Cell 5 한 번 이상 실행 필요)\n",
    "#\n",
    "# Output:\n",
    "#   results/csv/mp_policy_lut_mamba_wide_raw.csv      ← raw (smoothing 전)\n",
    "#   results/csv/mp_policy_lut_mamba_wide_pruned.csv   ← monotonic smoothed\n",
    "#   results/plots/exp1_pareto_accuracy_mamba_raw.png\n",
    "#   results/plots/exp1_pareto_accuracy_mamba_monotonic.png\n",
    "#\n",
    "# 소요시간: ~4-6h (GPU, 261 policies)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "import os\n",
    "csv_dir = \"results/csv\"\n",
    "for f in [\"mp_policy_lut_mamba_wide_raw.csv\",\n",
    "          \"mp_policy_lut_mamba_wide_pruned.csv\"]:\n",
    "    p = os.path.join(csv_dir, f)\n",
    "    if os.path.exists(p):\n",
    "        os.remove(p)\n",
    "        print(f\"Removed: {p}\")\n",
    "\n",
    "!pip install pulp -q\n",
    "\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_L2_dim512_baseline/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 512 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --decoder_layers 2 \\\n",
    "  --encoder_layers 2 \\\n",
    "  --batch-size 200 \\\n",
    "  --test-batch-size 200 \\\n",
    "  --num-workers 2 \\\n",
    "  --pq INT8 \\\n",
    "  --aq 8 \\\n",
    "  --act_quant 16 \\\n",
    "  --analyze_all \\\n",
    "  --wide_sweep \\\n",
    "  --wide_step 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ot3uvfq1yx9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 10: Fig. 2 — Offline Policy Refinement Ablation (CR=1/4, outdoor)\n",
    "#\n",
    "# (a) ILP-predicted vs KL-refined NMSE (monotonic-smoothed Pareto frontier)\n",
    "# (b) Discrepancy |NMSE_ILP - NMSE_KL-Ref|\n",
    "#\n",
    "# Prerequisites: Cell 9 완료 (wide CSV 존재)\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "CSV_DIR = \"results/csv\"\n",
    "pruned_path = os.path.join(CSV_DIR, \"mp_policy_lut_mamba_wide_pruned.csv\")\n",
    "assert os.path.exists(pruned_path), f\"Pruned CSV not found: {pruned_path}  <- Cell 9 먼저 실행\"\n",
    "\n",
    "df = pd.read_csv(pruned_path).sort_values(\"Actual_Saving\").reset_index(drop=True)\n",
    "x = df[\"Actual_Saving\"].values\n",
    "nmse_ilp = df[\"NMSE_ILP\"].values\n",
    "nmse_kl  = df[\"NMSE_KL\"].values\n",
    "disc     = np.abs(nmse_ilp - nmse_kl)\n",
    "\n",
    "# ── Figure 2: (a) + (b)  — solid lines + fill_between style ─────────────\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11, 'font.family': 'serif',\n",
    "    'mathtext.fontset': 'stix',\n",
    "    'axes.labelsize': 12, 'axes.titlesize': 13,\n",
    "})\n",
    "fig, (ax_a, ax_b) = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "\n",
    "# ── (a) ILP vs KL-Refined — solid lines ──────────────────────────────────\n",
    "ax_a.plot(x, nmse_ilp, 'b-s', label='ILP-predicted', markersize=3, linewidth=1.8, alpha=0.85)\n",
    "ax_a.plot(x, nmse_kl,  'r-o', label='KL-refined',    markersize=3, linewidth=1.8, alpha=0.85)\n",
    "ax_a.set_xlabel('BOPs Saving vs. FP32 (%)')\n",
    "ax_a.set_ylabel('NMSE (dB)')\n",
    "ax_a.set_title('(a) ILP vs. KL-Refined Policy')\n",
    "ax_a.legend(fontsize=10, loc='upper left')\n",
    "ax_a.grid(True, linestyle='--', alpha=0.35)\n",
    "\n",
    "# ── (b) Discrepancy — fill_between + line ─────────────────────────────────\n",
    "ax_b.fill_between(x, 0, disc, color='steelblue', alpha=0.3)\n",
    "ax_b.plot(x, disc, 'b-', linewidth=1.8, alpha=0.85)\n",
    "ax_b.set_xlabel('BOPs Saving vs. FP32 (%)')\n",
    "ax_b.set_ylabel('|NMSE_ILP - NMSE_KL-Ref| (dB)')\n",
    "ax_b.set_title('(b) ILP vs. KL-Refined Discrepancy')\n",
    "ax_b.grid(True, linestyle='--', alpha=0.35)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "out_png = \"results/plots/fig2_offline_ablation_mamba.png\"\n",
    "out_pdf = \"../figures/fig2_offline_ablation_mamba.pdf\"\n",
    "os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(out_pdf), exist_ok=True)\n",
    "fig.savefig(out_png, dpi=300, bbox_inches='tight')\n",
    "fig.savefig(out_pdf, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved: {out_png}\")\n",
    "print(f\"Saved: {out_pdf}\")\n",
    "plt.show()\n",
    "\n",
    "# ── Summary stats ─────────────────────────────────────────────────────────\n",
    "idx_max = np.argmax(disc)\n",
    "print(f\"\\n[Summary] {len(df)} policies (step ~{np.median(np.diff(x)):.2f}%)\")\n",
    "print(f\"  Max discrepancy: {disc.max():.2f} dB  @ {x[idx_max]:.1f}% saving\")\n",
    "print(f\"  Mean discrepancy: {disc.mean():.3f} dB\")\n",
    "print(f\"  Discrepancy > 0.5 dB: {(disc > 0.5).sum()} points\")\n",
    "print(f\"  Range where KL improves: {x[disc > 0.01][0]:.1f}% ~ {x[disc > 0.01][-1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecubli5pjuh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 11: Baselines (CRNet + CLNet) 0.05% Wide Sweep\n",
    "#\n",
    "# Prerequisites: Cell 1 완료\n",
    "# Output:\n",
    "#   MambaIC/results/csv/mp_policy_lut_crnet_cr4_out.csv  (덮어쓰기)\n",
    "#   MambaIC/results/csv/mp_policy_lut_clnet_cr4_out.csv  (덮어쓰기)\n",
    "#\n",
    "# 소요시간: ~1-2h (GPU, 2 models × ~261 policies)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression\n",
    "\n",
    "!pip install pulp -q\n",
    "\n",
    "!python rpmpq_baselines.py --wide_step 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urbmee2ul4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 12: CsiNet 0.05% Wide Sweep (Keras/TF)\n",
    "#\n",
    "# Prerequisites: Cell 1 완료\n",
    "# Output:\n",
    "#   MambaIC/results/csv/mp_policy_lut_csinet_cr4_out.csv  (덮어쓰기)\n",
    "#\n",
    "# 소요시간: ~30-60min (GPU, 1 model × ~261 policies)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/Python_CsiNet-master\n",
    "\n",
    "!python csinet_onlytest.py --env outdoor --analyze_all --wide_step 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51sboyrts25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 13: Ablation — ILP Granularity (num_chunks=8)\n",
    "#\n",
    "# FC layer를 8개 chunk로 분할 → ILP 변수 감소 → 계단식 staircase\n",
    "# KL refinement 효과가 극대화되는지 확인\n",
    "#\n",
    "# 기존 파일 덮어쓰지 않음 (별도 suffix: _nc8)\n",
    "# Output:\n",
    "#   results/csv/hawq_importance_split_nc8.csv\n",
    "#   results/csv/mp_policy_lut_mamba_wide_nc8_raw.csv\n",
    "#   results/csv/mp_policy_lut_mamba_wide_nc8_pruned.csv\n",
    "#\n",
    "# 소요시간: ~20-30min (GPU, ~131 policies at 0.1% step)\n",
    "# ============================================================\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "import os\n",
    "csv_dir = \"results/csv\"\n",
    "for f in [\"mp_policy_lut_mamba_wide_nc8_raw.csv\",\n",
    "          \"mp_policy_lut_mamba_wide_nc8_pruned.csv\"]:\n",
    "    p = os.path.join(csv_dir, f)\n",
    "    if os.path.exists(p):\n",
    "        os.remove(p)\n",
    "        print(f\"Removed: {p}\")\n",
    "\n",
    "!pip install pulp -q\n",
    "\n",
    "!python train_ae.py \\\n",
    "  --checkpoint \"saved_models/mamba_transnet_L2_dim512_baseline/best.pth\" \\\n",
    "  --encoder mamba \\\n",
    "  --decoder transnet \\\n",
    "  --encoded_dim 512 \\\n",
    "  --train_path data/DATA_Htrainout.mat \\\n",
    "  --test_path data/DATA_Htestout.mat \\\n",
    "  --epochs 0 \\\n",
    "  --decoder_layers 2 \\\n",
    "  --encoder_layers 2 \\\n",
    "  --batch-size 200 \\\n",
    "  --test-batch-size 200 \\\n",
    "  --num-workers 2 \\\n",
    "  --pq INT8 \\\n",
    "  --aq 8 \\\n",
    "  --act_quant 16 \\\n",
    "  --analyze_all \\\n",
    "  --wide_sweep \\\n",
    "  --wide_step 0.1 \\\n",
    "  --num_chunks 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gte8nkm2qmo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 14: Plot — num_chunks=8 vs 32 Ablation Comparison\n",
    "#\n",
    "# Prerequisites: Cell 9 (nc=32) + Cell 13 (nc=8) 완료\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%cd /content/drive/MyDrive/MambaCompression/MambaIC\n",
    "\n",
    "CSV_DIR = \"results/csv\"\n",
    "configs = {\n",
    "    \"nc=32 (default)\": os.path.join(CSV_DIR, \"mp_policy_lut_mamba_wide_pruned.csv\"),\n",
    "    \"nc=8  (coarse)\":  os.path.join(CSV_DIR, \"mp_policy_lut_mamba_wide_nc8_pruned.csv\"),\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11, 'font.family': 'serif',\n",
    "    'mathtext.fontset': 'stix',\n",
    "    'axes.labelsize': 12, 'axes.titlesize': 13,\n",
    "})\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for label, path in configs.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[SKIP] {label}: {path} not found\")\n",
    "        continue\n",
    "    df = pd.read_csv(path).sort_values(\"Actual_Saving\").reset_index(drop=True)\n",
    "    x = df[\"Actual_Saving\"].values\n",
    "    disc = np.abs(df[\"NMSE_ILP\"].values - df[\"NMSE_KL\"].values)\n",
    "\n",
    "    # (a) ILP vs KL\n",
    "    ax = axes[0]\n",
    "    style = '-' if 'default' in label else '--'\n",
    "    ax.plot(x, df[\"NMSE_ILP\"].values, f'b{style}', linewidth=1.5, alpha=0.7,\n",
    "            label=f'ILP ({label})')\n",
    "    ax.plot(x, df[\"NMSE_KL\"].values, f'r{style}', linewidth=1.5, alpha=0.7,\n",
    "            label=f'KL ({label})')\n",
    "\n",
    "    # (b) Discrepancy\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(x, disc, style, linewidth=1.8, label=label)\n",
    "    ax2.fill_between(x, 0, disc, alpha=0.15)\n",
    "\n",
    "    print(f\"[{label}] {len(df)} pts | Max disc: {disc.max():.2f} dB | Mean: {disc.mean():.3f} dB\")\n",
    "\n",
    "axes[0].set_xlabel('BOPs Saving vs. FP32 (%)')\n",
    "axes[0].set_ylabel('NMSE (dB)')\n",
    "axes[0].set_title('(a) ILP vs. KL-Refined Policy')\n",
    "axes[0].legend(fontsize=8, loc='upper left')\n",
    "axes[0].grid(True, linestyle='--', alpha=0.35)\n",
    "\n",
    "axes[1].set_xlabel('BOPs Saving vs. FP32 (%)')\n",
    "axes[1].set_ylabel('|NMSE_ILP - NMSE_KL-Ref| (dB)')\n",
    "axes[1].set_title('(b) Discrepancy: nc=32 vs nc=8')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, linestyle='--', alpha=0.35)\n",
    "\n",
    "fig.tight_layout()\n",
    "out = \"results/plots/fig2_ablation_nc8_vs_nc32.png\"\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nSaved: {out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000ef02",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 15: Empirical Validation of Lemma 1\n# \"Contractive SSM bounds quantization-induced state error\"\n#\n# Validates that per-token SSM state error ||e_t|| saturates\n# as token position t increases, confirming the bounded-error\n# guarantee under contractive state recursion (rho < 1).\n#\n# Uses the TRAINED model weights (A_logs, dt_projs, x_proj)\n# with random input — the contractivity is a weight property.\n#\n# Output: results/plots/lemma1_ssm_state_error.png\n#         ../figures/lemma1_ssm_state_error.pdf\n#\n# Prerequisites: Cell 1 (setup), trained model checkpoint\n# ============================================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os, sys, types\n\n%cd /content/drive/MyDrive/MambaCompression/MambaIC\nif '.' not in sys.path:\n    sys.path.insert(0, '.')\n\n# ── Workaround: Pre-load modules, bypassing models/__init__.py ────────\n# Problem: models/__init__.py imports MambaIC → compressai → torch_geometric → crash\n# Solution: Pre-load VSS_module and MambaAE directly into sys.modules\n#           so Python never needs to execute models/__init__.py\n\n# 1. Clear ALL cached models.* and related modules from previous runs\nfor _k in list(sys.modules.keys()):\n    if _k == 'models' or _k.startswith('models.'):\n        del sys.modules[_k]\nfor _k in ['ModularModels', 'MambaAE', 'VSS_module', 'csm_triton']:\n    sys.modules.pop(_k, None)\n\n# 2. Create minimal stub for models package\n_models_dir = os.path.join(os.getcwd(), 'models')\n_stub = types.ModuleType('models')\n_stub.__path__ = [_models_dir]\n_stub.__package__ = 'models'\nsys.modules['models'] = _stub\n\n# 3. Pre-load VSS_module from models/ directory (bypasses __init__.py)\n_orig_syspath = sys.path[:]\nsys.path.insert(0, _models_dir)\ntry:\n    import VSS_module\n    sys.modules['models.VSS_module'] = VSS_module\n    _stub.VSS_module = VSS_module\nfinally:\n    sys.path[:] = _orig_syspath\n\n# 4. Pre-load MambaAE (its 'from models.VSS_module' finds pre-loaded module)\nimport MambaAE\nsys.modules['models.MambaAE'] = MambaAE\n\n# ── 1. Load model ──────────────────────────────────────────────────────\nfrom ModularModels import ModularAE\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = ModularAE(encoder_type='mamba', decoder_type='transnet',\n                  encoded_dim=512, encoder_layers=2, decoder_layers=2)\nckpt = torch.load('saved_models/mamba_transnet_L2_dim512_baseline/best.pth',\n                   map_location='cpu')\nstate = ckpt.get('model_state_dict', ckpt.get('state_dict', ckpt))\nmodel.load_state_dict(state, strict=False)\nmodel = model.to(device).eval()\nprint(f\"[OK] Model loaded on {device}\")\n\n# ── 2. Random input (Lemma depends on weights, not data) ──────────────\nN_SAMPLES = 10\ntorch.manual_seed(42)\nx_test = torch.rand(N_SAMPLES, 2, 32, 32, device=device)\nprint(f\"[OK] Random input: {x_test.shape}\")\n\n# ── 3. Forward through encoder stem to get SS2D input ─────────────────\nfrom einops import rearrange\n\nmamba_blk = model.encoder.layers[0]   # first ChunkedResidualMambaBlock\nss2d      = mamba_blk.vss[1]          # SS2D module (index 1 in Sequential)\n\nwith torch.no_grad():\n    x_stem = model.encoder.stem(x_test)\n    x_norm = mamba_blk.norm(x_stem)\n    x_act  = mamba_blk.act(x_norm)\n    cs = mamba_blk.chunk_size\n    x_chunked = rearrange(x_act,\n        'b c (h cs_h) (w cs_w) -> (b h w) c cs_h cs_w',\n        cs_h=cs, cs_w=cs)\n    x_bhwc = x_chunked.permute(0, 2, 3, 1).contiguous()\n    xz = ss2d.in_proj(x_bhwc)\n    d_inner = xz.shape[-1] // 2\n    x_proj = xz[..., :d_inner]\n    z_gate = ss2d.act(xz[..., d_inner:])\n    x_conv = x_proj.permute(0, 3, 1, 2).contiguous()\n    x_conv = ss2d.act(ss2d.conv2d(x_conv))\n\nB_sz, D_dim, H, W = x_conv.shape\nL      = H * W\nK      = 4\nN_s    = ss2d.A_logs.shape[1]\nR      = ss2d.dt_projs_weight.shape[2]\nprint(f\"[OK] SS2D input: B={B_sz}, D={D_dim}, H={H}, W={W}, L={L}, K={K}, N={N_s}, R={R}\")\n\n# ── 4. Helper: symmetric quantization ─────────────────────────────────\ndef quantize_sym(x, bits):\n    if bits >= 32: return x.clone()\n    abs_max = x.abs().max()\n    if abs_max == 0: return x.clone()\n    qmax = 2**(bits - 1) - 1\n    scale = abs_max / qmax\n    return torch.round(x / scale).clamp(-qmax, qmax) * scale\n\n# ── 5. Compute projected SSM tensors (FP32 or quantized weights) ──────\nfrom models.VSS_module import CrossScan\n\ndef compute_ssm_tensors(ss2d, x_conv, w_bits=32):\n    B, D, H, W = x_conv.shape\n    L, K, N, R = H*W, 4, ss2d.A_logs.shape[1], ss2d.dt_projs_weight.shape[2]\n\n    xpw  = ss2d.x_proj_weight.data.float()\n    dtpw = ss2d.dt_projs_weight.data.float()\n    dtpb = ss2d.dt_projs_bias.data.float()\n    alg  = ss2d.A_logs.data.float()\n    ds   = ss2d.Ds.data.float()\n\n    if w_bits < 32:\n        xpw  = quantize_sym(xpw, w_bits)\n        dtpw = quantize_sym(dtpw, w_bits)\n        alg  = quantize_sym(alg, w_bits)\n\n    xs = CrossScan.apply(x_conv).view(B, K, D, L).float()\n    x_dbl = torch.einsum(\"bkdl, kcd -> bkcl\", xs, xpw)\n    dts_r, Bs, Cs = torch.split(x_dbl, [R, N, N], dim=2)\n    dts = torch.einsum(\"bkrl, kdr -> bkdl\", dts_r, dtpw)\n\n    As = -torch.exp(alg)\n    db = dtpb.view(-1)\n\n    return (xs.reshape(B, K*D, L), dts.reshape(B, K*D, L),\n            As, Bs.contiguous(), Cs.contiguous(), ds, db)\n\n# ── 6. Manual selective scan (records all intermediate states) ─────────\ndef manual_ssm_dir(u, delta, A, B, C, D_skip, db, k, D):\n    B_sz, _, L = u.shape\n    N = A.shape[1]\n    sl = slice(k*D, (k+1)*D)\n\n    u_k, dt_k = u[:, sl, :], delta[:, sl, :]\n    A_k, B_k, C_k = A[sl, :], B[:, k, :, :], C[:, k, :, :]\n    D_k, db_k = D_skip[sl], db[sl]\n\n    states = torch.zeros(B_sz, D, L, N, device=u.device)\n    y      = torch.zeros(B_sz, D, L, device=u.device)\n    s      = torch.zeros(B_sz, D, N, device=u.device)\n\n    for t in range(L):\n        dt  = F.softplus(dt_k[:, :, t] + db_k)\n        dA  = torch.exp(dt.unsqueeze(-1) * A_k)\n        dBu = (dt.unsqueeze(-1)\n               * B_k[:, :, t].unsqueeze(1)\n               * u_k[:, :, t].unsqueeze(-1))\n        s = dA * s + dBu\n        states[:, :, t, :] = s\n        y[:, :, t] = ((C_k[:, :, t].unsqueeze(1) * s).sum(-1)\n                       + D_k * u_k[:, :, t])\n    return y, states\n\n# ── 7. Run FP32 baseline ──────────────────────────────────────────────\nprint(\"\\nRunning FP32 baseline SSM loop (4 dirs x 64 tokens)...\")\nwith torch.no_grad():\n    xs_fp, dts_fp, As_fp, Bs_fp, Cs_fp, Ds_fp, db_fp = \\\n        compute_ssm_tensors(ss2d, x_conv, w_bits=32)\n\nfp32_states, fp32_y = {}, {}\nfor k in range(K):\n    y_k, s_k = manual_ssm_dir(xs_fp, dts_fp, As_fp, Bs_fp, Cs_fp, Ds_fp, db_fp, k, D_dim)\n    fp32_states[k] = s_k\n    fp32_y[k] = y_k\nprint(\"  Done.\")\n\n# ── 8. Run quantized versions ─────────────────────────────────────────\nbit_configs = [16, 8, 4, 2]\nresults = {}\n\nfor bits in bit_configs:\n    print(f\"  W{bits}...\", end=\"\", flush=True)\n    with torch.no_grad():\n        xs_q, dts_q, As_q, Bs_q, Cs_q, Ds_q, db_q = \\\n            compute_ssm_tensors(ss2d, x_conv, w_bits=bits)\n\n    state_errs, output_errs = [], []\n    for k in range(K):\n        y_q, s_q = manual_ssm_dir(xs_q, dts_q, As_q, Bs_q, Cs_q, Ds_q, db_q, k, D_dim)\n        se = (fp32_states[k] - s_q).norm(dim=-1).mean(dim=(0, 1))\n        oe = (fp32_y[k] - y_q).abs().mean(dim=(0, 1))\n        state_errs.append(se)\n        output_errs.append(oe)\n\n    results[bits] = {\n        'state_err':  torch.stack(state_errs).mean(0).cpu().numpy(),\n        'output_err': torch.stack(output_errs).mean(0).cpu().numpy(),\n    }\n    se_plat = results[bits]['state_err'][-5:].mean()\n    oe_plat = results[bits]['output_err'][-5:].mean()\n    print(f\" state_plateau={se_plat:.4f}, output_plateau={oe_plat:.4f}\")\n\n# ── 9. Contractivity check ────────────────────────────────────────────\nwith torch.no_grad():\n    dt_vals = F.softplus(dts_fp[:, :D_dim, :] + db_fp[:D_dim][None, :, None])\n    dA_vals = torch.exp(dt_vals.unsqueeze(-1) * As_fp[:D_dim][None, :, None, :])\n    rho_max  = dA_vals.max().item()\n    rho_99   = dA_vals.quantile(0.99).item()\n    rho_mean = dA_vals.mean().item()\n\nprint(f\"\\n{'='*55}\")\nprint(f\" Contractivity Verification  (direction k=0)\")\nprint(f\"{'='*55}\")\nprint(f\"  max  exp(Delta*A) = {rho_max:.6f}   {'< 1 OK' if rho_max < 1 else '>= 1 WARNING'}\")\nprint(f\"  99th exp(Delta*A) = {rho_99:.6f}\")\nprint(f\"  mean exp(Delta*A) = {rho_mean:.6f}\")\n\nprint(f\"\\n{'='*55}\")\nprint(f\" Error Saturation Analysis\")\nprint(f\"{'='*55}\")\nfor bits in bit_configs:\n    se = results[bits]['state_err']\n    plateau = se[-5:].mean()\n    thresh = 0.95 * plateau\n    t_stable = np.argmax(se >= thresh) if plateau > 1e-10 else 0\n    print(f\"  W{bits:2d}: plateau = {plateau:.4f} | 95% reached at t = {t_stable}\")\n\n# ── 10. Plot ───────────────────────────────────────────────────────────\nplt.rcParams.update({\n    'font.family': 'serif', 'font.size': 11,\n    'mathtext.fontset': 'stix',\n    'axes.labelsize': 12, 'axes.titlesize': 13,\n})\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5))\ncolors = {16: '#2196F3', 8: '#FF9800', 4: '#E91E63', 2: '#9C27B0'}\ntokens = np.arange(L)\n\nfor bits in bit_configs:\n    ax1.plot(tokens, results[bits]['state_err'], color=colors[bits],\n             linewidth=1.8, label=f'W{bits}', alpha=0.85)\n    ax2.plot(tokens, results[bits]['output_err'], color=colors[bits],\n             linewidth=1.8, label=f'W{bits}', alpha=0.85)\n\nax1.set_xlabel('Token position $t$')\nax1.set_ylabel(r'$\\Vert \\mathbf{e}_t \\Vert_2 = '\n               r'\\Vert \\mathbf{s}_t^{\\mathrm{FP32}} '\n               r'- \\mathbf{s}_t^{\\mathrm{Q}} \\Vert_2$')\nax1.set_title('(a) SSM State Error')\nax1.legend(fontsize=10)\nax1.grid(True, ls='--', alpha=0.3)\nax1.text(0.97, 0.05,\n         f'$\\\\rho_{{\\\\max}}={rho_max:.4f}$\\n$\\\\bar{{\\\\rho}}={rho_mean:.4f}$',\n         transform=ax1.transAxes, ha='right', va='bottom', fontsize=9,\n         bbox=dict(boxstyle='round,pad=0.3', fc='wheat', alpha=0.5))\n\nax2.set_xlabel('Token position $t$')\nax2.set_ylabel(r'$| y_t^{\\mathrm{FP32}} - y_t^{\\mathrm{Q}} |$')\nax2.set_title('(b) SSM Output Error')\nax2.legend(fontsize=10)\nax2.grid(True, ls='--', alpha=0.3)\n\nfig.suptitle('Lemma 1 Validation: Contractive SSM bounds '\n             'quantization error propagation',\n             fontsize=12, y=1.02)\nfig.tight_layout()\n\nout_png = \"results/plots/lemma1_ssm_state_error.png\"\nout_pdf = \"../figures/lemma1_ssm_state_error.pdf\"\nos.makedirs(os.path.dirname(out_png), exist_ok=True)\nos.makedirs(os.path.dirname(out_pdf), exist_ok=True)\nfig.savefig(out_png, dpi=300, bbox_inches='tight')\nfig.savefig(out_pdf, dpi=300, bbox_inches='tight')\nprint(f\"\\nSaved: {out_png}\")\nprint(f\"Saved: {out_pdf}\")\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}