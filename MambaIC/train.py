# íŒŒì¼ ì´ë¦„: train_ae.py
# (CsiNet ë²¤ì¹˜ë§ˆí¬ìš©. "0-Mean, 1-Power" ì •ê·œí™” ì‚¬ìš©)
# (â—ï¸ ì´ íŒŒì¼ì€ ìˆ˜ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤ â—ï¸)

import os, sys
# âœ… í˜„ì¬ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.append(project_root)

models_path = os.path.join(project_root, "models")
if models_path not in sys.path:
    sys.path.append(models_path)
    
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
import numpy as np
import os
import argparse
from tqdm import tqdm
import scipy.io as sio
import math
import logging
import sys
import time
from datetime import datetime
import torch.nn.functional as F # (Clampë¥¼ ìœ„í•´ ì„í¬íŠ¸)

# --- (í•µì‹¬!) MambaAE ëª¨ë¸ ì„í¬íŠ¸ ---
try:
    from MambaAE import MambaAE
    print("from MambaAE import MambaAE ì„í¬íŠ¸ ì„±ê³µ.")
except ImportError as e:
    print(f"ì˜¤ë¥˜: {e}. MambaAE.py íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# ----------------------------------------------------
# 1. CsiDataset (ìˆ˜ì •: Power-Scaling ì •ê·œí™”)
# (â—ï¸ CsiNet ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•´ "0-Mean, 1-Power"ë¥¼ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„í•œ ë²„ì „)
# ----------------------------------------------------
class CsiDataset(Dataset):
    def __init__(self, mat_file_path, data_key='HT', max_samples=None, normalization_factor=None):
        super(CsiDataset, self).__init__()
        self.mat_file_path = mat_file_path
        print(f"Loading .mat file: {self.mat_file_path} (key: {data_key}) ...")
        try:
            mat_data = sio.loadmat(self.mat_file_path)
            self.csi_data = np.array(mat_data[data_key], dtype=np.float32)
        except Exception as e:
            print(f"Error loading {mat_file_path}: {e}")
            raise
        print(f"Data loaded (flat). Shape: {self.csi_data.shape}")
        
        # â—ï¸(ìˆ˜ì •) Reshapeì„ ë‚˜ì¤‘ì— í•˜ê³ , íŒŒì›Œ ê³„ì‚°ì€ ì „ì²´ ë°ì´í„°ë¡œ
        try:
            csi_data_reshaped = np.reshape(self.csi_data, (self.csi_data.shape[0], 2, 32, 32))
        except Exception as e:
            print(f"Reshape Error: {e}"); raise
        
        # 1. 0-Mean (Re-center)
        csi_data_centered = csi_data_reshaped - 0.5
        
        # 2. Power-Scaling (CsiNet ë²¤ì¹˜ë§ˆí¬ ë°©ì‹)
        if normalization_factor is None:
            # (í›ˆë ¨ì…‹) ì „ì²´ ë°ì´í„°ì…‹ì˜ í‰ê·  íŒŒì›Œ(ë¶„ì‚°) ê³„ì‚°
            avg_power = np.mean(csi_data_centered ** 2)
            self.scale_factor = np.sqrt(avg_power)
            print(f"Calculated 0-Mean data. Avg Power: {avg_power:.4f}, Scale Factor (std): {self.scale_factor:.4f}")
        else:
            # (í…ŒìŠ¤íŠ¸ì…‹) í›ˆë ¨ì…‹ì˜ ìŠ¤ì¼€ì¼ íŒ©í„° ì‚¬ìš©
            self.scale_factor = normalization_factor
            print(f"Using Train Scale Factor (std): {self.scale_factor:.4f}")
            
        # 3. ë°ì´í„° ì •ê·œí™” ì ìš© (â—ï¸ Z-Score ë°ì´í„° ìƒì„±)
        self.csi_data_normalized = csi_data_centered / self.scale_factor
        
        # 4. (ìˆ˜ì •) max_samples ì ìš© (ì •ê·œí™” *ì´í›„ì—*)
        if max_samples is not None:
            if self.csi_data_normalized.shape[0] > max_samples:
                self.csi_data = self.csi_data_normalized[:max_samples]
                print(f"--- TOY PROJECT MODE: ë°ì´í„°ê°€ {max_samples}ê°œë¡œ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤ ---")
            else:
                self.csi_data = self.csi_data_normalized
        else:
            self.csi_data = self.csi_data_normalized
            
        print(f"Data Normalized (0-Mean, 1-Power). Min: {np.min(self.csi_data):.4f}, Max: {np.max(self.csi_data):.4f}, Mean: {np.mean(self.csi_data):.4f}, Std: {np.std(self.csi_data):.4f}")

    def __len__(self):
        return self.csi_data.shape[0]

    def __getitem__(self, idx):
        csi_sample = self.csi_data[idx] # (2, 32, 32), 0-Mean, 1-Power (Z-Score)
        return torch.from_numpy(csi_sample) 

# --- (AverageMeterëŠ” ë™ì¼) ---
class AverageMeter:
    def __init__(self):
        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0
    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

# --- (NMSE ê³„ì‚° í•¨ìˆ˜ëŠ” ë²¤ì¹˜ë§ˆí¬ì™€ 100% ë™ì¼) ---
def calculate_nmse_db(original_data, reconstructed_data):
    """
    Calculates NMSE in dB on 0-mean, 1-power normalized data.
    NMSE_dB = 10 * log10( sum( (d - d_hat)^2 ) / sum( d^2 ) )
    (ì´ì œ NMSE_dB = 10 * log10(MSE) ì™€ ê±°ì˜ ë™ì¼)
    """
    original_power = torch.sum(original_data**2, dim=[1, 2, 3])
    mse = torch.sum((original_data - reconstructed_data)**2, dim=[1, 2, 3])
    
    valid_indices = original_power > 1e-8
    if torch.sum(valid_indices) == 0: return torch.tensor(-100.0)
    
    nmse = torch.mean(mse[valid_indices] / original_power[valid_indices])
    
    if nmse.item() <= 1e-10: return torch.tensor(-100.0)
    nmse_db = 10 * torch.log10(nmse)
    return nmse_db

# --- (ì˜µí‹°ë§ˆì´ì €) ---
def configure_optimizer_ae(net, args):
    # ğŸ”§ (ìˆ˜ì •) ì œì•ˆëœ Adam Beta ê°’ ì ìš©
    optimizer = optim.Adam(net.parameters(), lr=args.learning_rate, betas=(0.9, 0.99))
    return optimizer

# ğŸ”§ (ì‹ ê·œ) Warm-up ë©”ì‹œì§€ ì¤‘ë³µ ë°©ì§€ í—¬í¼
_WARMUP_PRINTED_TRAIN = False
_WARMUP_PRINTED_VAL = False

# ğŸ”§ (ì‹ ê·œ) nn.DataParallelì„ ì²˜ë¦¬í•˜ëŠ” ì†ì„± ì„¤ì • í—¬í¼
def set_quant_status(model, disable_quant: bool):
    """ëª¨ë¸ì´ DataParallelë¡œ ë˜í•‘ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  disable_quant ì†ì„±ì„ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •í•©ë‹ˆë‹¤."""
    if isinstance(model, nn.DataParallel):
        model.module.disable_quant = disable_quant
    else:
        model.disable_quant = disable_quant

# --- (í•™ìŠµ í•¨ìˆ˜: ğŸ”§ Warm-up í”Œë˜ê·¸ ì„¤ì • ìˆ˜ì •) ---
def train_one_epoch_ae(model, mse_loss_fn, train_dataloader, optimizer, epoch, clip_max_norm, args):
    model.train()
    
    # ğŸ”§ (ì‹ ê·œ) Quantization Warm-up í”Œë˜ê·¸ ì„¤ì • (args.warmup_epochs ì‚¬ìš©)
    global _WARMUP_PRINTED_TRAIN, _WARMUP_PRINTED_VAL
    if epoch < args.warmup_epochs:
        set_quant_status(model, True) # ğŸ”§ DataParallel ë²„ê·¸ ìˆ˜ì •
        if not _WARMUP_PRINTED_TRAIN:
            print(f"--- [Train] Quantization WARM-UP enabled (Epoch < {args.warmup_epochs}) ---", flush=True)
            _WARMUP_PRINTED_TRAIN = True
    else:
        set_quant_status(model, False) # ğŸ”§ DataParallel ë²„ê·¸ ìˆ˜ì •
        if _WARMUP_PRINTED_TRAIN: # ì›œì—…ì´ ëë‚˜ëŠ” ì‹œì ì— í•œ ë²ˆë§Œ ì¶œë ¥
            print(f"--- [Train] Quantization WARM-UP disabled (Epoch >= {args.warmup_epochs}) ---", flush=True)
            _WARMUP_PRINTED_TRAIN = False # í”Œë˜ê·¸ ë¦¬ì…‹
            _WARMUP_PRINTED_VAL = False # ê²€ì¦ í”Œë˜ê·¸ë„ í•¨ê»˜ ë¦¬ì…‹
    
    device = next(model.parameters()).device
    pbar = tqdm(train_dataloader, desc=f"Epoch {epoch+1} [Train]")
    
    for d in pbar:
        d = d.to(device) # dëŠ” ì´ì œ 0-mean, 1-power
        optimizer.zero_grad()
        x_hat = model(d) # x_hatë„ 0-mean, 1-power (BatchNormì´ ìŠ¤ì¼€ì¼ë§)
        loss = mse_loss_fn(x_hat, d)
        if torch.isnan(loss):
            print("Warning: Loss is NaN, skipping batch"); continue
        loss.backward()
        if clip_max_norm > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_max_norm)
        optimizer.step()
        pbar.set_postfix(MSE_Loss=f"{loss.item():.8f}")

# ----------------------------------------------------
# 2. test_epoch_ae (ğŸ”§ Warm-up í”Œë˜ê·¸ ì„¤ì • ìˆ˜ì •)
# ----------------------------------------------------
def test_epoch_ae(epoch, test_dataloader, model, mse_loss_fn, args): # ğŸ”§ args ì¶”ê°€
    model.eval()
    
    # ğŸ”§ (ì¹˜ëª…ì  ë²„ê·¸ ìˆ˜ì •) ê²€ì¦ í•¨ìˆ˜ì—ë„ Warm-up í”Œë˜ê·¸ë¥¼ ë™ì¼í•˜ê²Œ ì ìš©
    global _WARMUP_PRINTED_VAL
    if epoch < args.warmup_epochs:
        set_quant_status(model, True) # ğŸ”§ DataParallel ë²„ê·¸ ìˆ˜ì •
        if not _WARMUP_PRINTED_VAL:
            print(f"--- [Val] Quantization WARM-UP enabled (Epoch < {args.warmup_epochs}) ---", flush=True)
            _WARMUP_PRINTED_VAL = True
    else:
        set_quant_status(model, False) # ğŸ”§ DataParallel ë²„ê·¸ ìˆ˜ì •
        
    device = next(model.parameters()).device
    mse_loss = AverageMeter()
    nmse_db = AverageMeter()
    
    with torch.no_grad():
        pbar = tqdm(test_dataloader, desc=f"Epoch {epoch+1} [Val]")
        for d in pbar:
            d = d.to(device) # dëŠ” 0-mean, 1-power
            x_hat = model(d) # x_hatì€ 0-mean, 1-power
            
            # â—ï¸ (ìˆ˜ì •) clamp ì œê±°
            
            loss_val = mse_loss_fn(x_hat, d)
            
            original_csi_norm = d
            decoded_csi_norm = x_hat
            
            nmse_val = calculate_nmse_db(original_csi_norm, decoded_csi_norm)
            
            mse_loss.update(loss_val.item())
            nmse_db.update(nmse_val.item())
            
            pbar.set_postfix(NMSE_dB=f"{nmse_db.avg:.4f}", MSE=f"{mse_loss.avg:.8f}")
            
    print(f"--- [ê²°ê³¼] Epoch {epoch+1} ---")
    print(f"  Test MSE (ì„±ëŠ¥): {mse_loss.avg:.8f}")
    print(f"  Test NMSE (ì„±ëŠ¥): {nmse_db.avg:.4f} dB")
    return nmse_db.avg

# --- (main í•¨ìˆ˜ëŠ” ë™ì¼) ---
def parse_args(argv):
    parser = argparse.ArgumentParser(description="Mamba-AE (Fixed Rate) for CSI Compression.")
    parser.add_argument("--train_path", type=str, default="data/DATA_Htrainin.mat")
    parser.add_argument("--train_key", type=str, default="HT")
    parser.add_argument("--test_path", type=str, default="data/DATA_Htestin.mat")
    parser.add_argument("--test_key", type=str, default="HT")
    parser.add_argument("--N", type=int, default=128)
    parser.add_argument("--M", type=int, default=320, help="Latent channels (CR control)")
    parser.add_argument("--bits", type=int, default=8, help="Number of quantization bits for the latent space.")
    parser.add_argument("--depths", nargs='+', type=int, default=[2, 2, 9, 2])
    parser.add_argument("-e", "--epochs", default=100, type=int)
    parser.add_argument("-lr", "--learning-rate", default=1e-4, type=float)
    parser.add_argument("-n", "--num-workers", type=int, default=2)
    parser.add_argument("--batch-size", type=int, default=16)
    parser.add_argument("--test-batch-size", type=int, default=16) 
    parser.add_argument("--cuda", action="store_true", default=True)
    parser.add_argument("--save", action="store_true", default=True)
    parser.add_argument("--seed", type=float, default=42)
    parser.add_argument("--clip_max_norm", default=1.0, type=float)
    parser.add_argument("--checkpoint", type=str, help="Path to a checkpoint")
    parser.add_argument("--lr_epoch", nargs='+', type=int, default=[80, 100])
    # ğŸ”§ (ì‹ ê·œ) Warm-up Epochs ì¸ì ì¶”ê°€
    parser.add_argument("--warmup_epochs", type=int, default=3, help="Number of epochs to train without quantization.")
    args = parser.parse_args(argv)
    return args

def main(argv):
    args = parse_args(argv)
    print(f"--- Mamba-AE (Fixed Rate) Training (2-Ch): {datetime.now()} ---")
    print(f"â—ï¸ Fixed Rate (CsiNet-style). Latent M={args.M}, Bits={args.bits}")
    print(f"â—ï¸ Normalization: 0-Mean, 1-Power (CsiNet Benchmark Standard)")
    print(f"â—ï¸ Quantization Warm-up: {args.warmup_epochs} Epochs")
    
    if args.seed is not None:
        torch.manual_seed(args.seed); np.random.seed(args.seed)
    device = "cuda" if args.cuda and torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    # --- 1. ë°ì´í„° ë¡œë” (ìˆ˜ì •: í›ˆë ¨ì…‹/í…ŒìŠ¤íŠ¸ì…‹ ì •ê·œí™”) ---
    print("Loading datasets...")
    # â—ï¸ (ìˆ˜ì •) í›ˆë ¨ì…‹ ë¡œë“œ
    train_dataset = CsiDataset(args.train_path, args.train_key, max_samples=300)
    # â—ï¸ (ìˆ˜ì •) í›ˆë ¨ì…‹ì—ì„œ ê³„ì‚°ëœ ìŠ¤ì¼€ì¼ íŒ©í„° ê°€ì ¸ì˜¤ê¸°
    train_scale_factor = train_dataset.scale_factor 
    # â—ï¸ (ìˆ˜ì •) í…ŒìŠ¤íŠ¸ì…‹ ë¡œë“œ ì‹œ ìŠ¤ì¼€ì¼ íŒ©í„° ì „ë‹¬
    test_dataset = CsiDataset(args.test_path, args.test_key, max_samples=100, normalization_factor=train_scale_factor)
    
    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True, pin_memory=(device == "cuda"))
    test_dataloader = DataLoader(test_dataset, batch_size=args.test_batch_size, num_workers=args.num_workers, shuffle=False, pin_memory=(device == "cuda")) 

    # --- 2. ëª¨ë¸ ë¡œë“œ (MambaAE) ---
    print(f"Creating MambaAE model (N={args.N}, M={args.M}, depths={args.depths}, bits={args.bits})")
    net = MambaAE(depths=args.depths, N=args.N, M=args.M, bits=args.bits)
    net = net.to(device)
    if args.cuda and torch.cuda.device_count() > 1:
        print(f"Using {torch.cuda.device_count()} GPUs (nn.DataParallel)")
        net = nn.DataParallel(net)

    # --- 3. ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤ í•¨ìˆ˜ (MSE) ---
    optimizer = configure_optimizer_ae(net, args)
    lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, args.lr_epoch, gamma=0.1)
    mse_loss_fn = nn.MSELoss() 

    # --- 4. ì²´í¬í¬ì¸íŠ¸ ---
    last_epoch = 0
    if args.checkpoint:
        print("Loading", args.checkpoint)
        checkpoint = torch.load(args.checkpoint, map_location=device)
        # ğŸ”§ DataParallel ë¡œë“œ í˜¸í™˜
        state_dict = checkpoint["state_dict"]
        if isinstance(net, nn.DataParallel) and not list(state_dict.keys())[0].startswith('module.'):
            state_dict = {'module.' + k: v for k, v in state_dict.items()}
        elif not isinstance(net, nn.DataParallel) and list(state_dict.keys())[0].startswith('module.'):
            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        net.load_state_dict(state_dict)
        
        last_epoch = checkpoint["epoch"] + 1
        optimizer.load_state_dict(checkpoint["optimizer"])
        lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])

    # --- 5. í•™ìŠµ ë° í‰ê°€ ë£¨í”„ ---
    best_nmse = float("inf")
    # ğŸ§© (ìˆ˜ì •) ì €ì¥ ê²½ë¡œì— ë¹„íŠ¸ ìˆ˜ ì¶”ê°€
    save_path = f"saved_models/csi_mamba_AE_M{args.M}_bits{args.bits}/" 
    if args.save:
        os.makedirs(save_path, exist_ok=True) 

    for epoch in range(last_epoch, args.epochs):
        print(f"Learning rate: {optimizer.param_groups[0]['lr']}")
        
        train_one_epoch_ae(
            net, mse_loss_fn, train_dataloader, optimizer, epoch, args.clip_max_norm, args
        )
        
        # ğŸ”§ (ìˆ˜ì •) test_epoch_aeì— args ì „ë‹¬
        nmse_db = test_epoch_ae(epoch, test_dataloader, net, mse_loss_fn, args)
        lr_scheduler.step()

        is_best = nmse_db < best_nmse
        best_nmse = min(nmse_db, best_nmse)

        if args.save:
            # ğŸ”§ DataParallel ì €ì¥ í˜¸í™˜
            state = {"epoch": epoch, "nmse_db": nmse_db,
                     "optimizer": optimizer.state_dict(),
                     "lr_scheduler": lr_scheduler.state_dict()}
            if isinstance(net, nn.DataParallel):
                state["state_dict"] = net.module.state_dict()
            else:
                state["state_dict"] = net.state_dict()
                
            torch.save(state, os.path.join(save_path, "checkpoint_latest.pth.tar"))
            if is_best:
                print(f"  âœ¨ ìµœê³  NMSE ê°±ì‹ : {best_nmse:.4f} dB. ëª¨ë¸ ì €ì¥.")
                torch.save(state, os.path.join(save_path, "checkpoint_best.pth.tar"))

if __name__ == "__main__":
    main(sys.argv[1:])